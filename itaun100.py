# -*- coding: utf-8 -*-
"""itaun100.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EayNGI6RvVw-hWZc3KweRayG7YSmZkwc
"""

# Célula 1: Instalação e Importações
!pip install yfinance pandas
import yfinance as yf
import pandas as pd
import numpy as np
import datetime as dt
from tqdm.notebook import tqdm # Para barras de progresso
import warnings

# Ignorar avisos futuros do Pandas/Yfinance para manter a saída limpa
warnings.simplefilter(action='ignore', category=FutureWarning)

# Célula 2: Definição do Universo (NASDAQ-100)

# AVISO METODOLÓGICO:
# Esta é a lista de constituintes ATUAL (Outubro/2025).
# O uso desta lista para um backtest histórico introduz VIÉS DE SOBREVIVÊNCIA.
# Deve ser declarado como uma limitação no relatório final.

# Lista de tickers do NASDAQ-100 (Excluindo duplicatas como GOOG/GOOGL por simplicidade inicial)
# Esta lista pode precisar de pequenas atualizações.
tickers_n100 = [
    'AAPL', 'MSFT', 'AMZN', 'NVDA', 'META', 'GOOGL', 'TSLA', 'AVGO', 'COST',
    'ADBE', 'AMD', 'PEP', 'CSCO', 'NFLX', 'CMCSA', 'INTC', 'TMUS', 'TXN',
    'QCOM', 'AMGN', 'HON', 'INTU', 'AMAT', 'BKNG', 'SBUX', 'ISRG', 'GILD',
    'MDLZ', 'ADI', 'LRCX', 'REGN', 'PYPL', 'VRTX', 'CSX', 'PANW', 'MU',
    'SNPS', 'CDNS', 'MAR', 'ASML', 'KLAC', 'CHTR', 'MRNA', 'ORLY', 'AEP',
    'FTNT', 'KDP', 'MNST', 'ABNB', 'PAYX', 'EXC', 'CTAS', 'ROP', 'DXCM',
    'PDD', 'ROST', 'CPRT', 'PCAR', 'MCHP', 'AZN', 'LULU', 'MELI', 'WDAY',
    'IDXX', 'CRWD', 'CEG', 'FAST', 'ON', 'KHC', 'WBD', 'GEHC', 'TTD', 'VRSK',
    'CSGP', 'XEL', 'CTSH', 'BKR', 'GFS', 'ANSS', 'DDOG', 'MRVL', 'EA',
    'WBA', 'ODFL', 'BIIB', 'FANG', 'RIVN', 'DLTR', 'ALGN', 'ZM', 'ILMN',
    'SIRI', 'ZS', 'ENPH', 'TEAM', 'LCID'
]

print(f"Universo definido com {len(tickers_n100)} tickers.")

# Célula 3: Coleta de Dados de Mercado (Preços)

# Definindo o período do backtest (15 anos)
start_date = '2010-01-01'
end_date = dt.date.today().strftime('%Y-%m-%d') # Até a data de hoje

print(f"Baixando dados de preços D1 para {len(tickers_n100)} tickers...")
print(f"Período: {start_date} a {end_date}")

# O Yfinance baixa todos de uma vez; 'Adj Close' é usado para retornos
# mas usaremos 'Close' e 'Open' brutos para o cálculo do gap.
try:
    price_data = yf.download(tickers_n100, start=start_date, end=end_date)

    if price_data.empty:
        print("\nERRO: Nenhum dado de preço foi baixado. Verifique a conexão ou os tickers.")
    else:
        print("\nDownload de preços concluído.")
        # Verificando a estrutura dos dados
        print("Estrutura dos dados (colunas):")
        print(price_data.columns.names)
        print("Exemplo de dados (head):")
        print(price_data.head())

except Exception as e:
    print(f"\nOcorreu um erro no download: {e}")

# Célula 3.1 (NOVA): Limpeza do Universo de Tickers

# Identifica colunas (tickers) que são inteiramente NaN (falha no download)
all_nan_tickers = price_data['Close'].columns[price_data['Close'].isna().all()].tolist()

if all_nan_tickers:
    print(f"Tickers com falha no download (ex: {all_nan_tickers}) serão removidos do universo.")

    # Filtra o DataFrame de preços, removendo os tickers com falha
    # O 'level=1' informa ao pandas para procurar o ticker no segundo nível do MultiIndex
    price_data = price_data.drop(columns=all_nan_tickers, level=1)

    # Atualiza a lista de tickers que usaremos daqui para frente
    tickers_n100_clean = [t for t in tickers_n100 if t not in all_nan_tickers]

    print(f"Universo de tickers limpo. Total: {len(tickers_n100_clean)} tickers.")

    # Validação cruzada com o seu log de erro
    if 'ANSS' in all_nan_tickers or 'REGN' in all_nan_tickers:
         print("Validação: Tickers reportados no log de erro ('ANSS', 'REGN') foram removidos.")
else:
    print("Download de preços foi bem-sucedido para todos os tickers.")
    tickers_n100_clean = tickers_n100

# Célula 4 (REVISADA): Coleta e PADRONIZAÇÃO das Datas de Earnings

print(f"Buscando calendário de 'earnings' para {len(tickers_n100_clean)} tickers limpos...")

earnings_calendar = {}
failed_tickers = []

for ticker_str in tqdm(tickers_n100_clean, desc="Buscando Calendários"):
    try:
        ticker_obj = yf.Ticker(ticker_str)
        all_dates = []

        # 1. TENTATIVA PRIORITÁRIA: .earnings_dates (retorna histórico)
        # É a nossa fonte principal de dados
        earnings_dates_df = ticker_obj.earnings_dates
        if not earnings_dates_df.empty:
            # PADRONIZAÇÃO: Converte Timestamp do pandas para datetime.date
            all_dates = [d.date() for d in earnings_dates_df.index.tolist()]

        # 2. TENTATIVA FALLBACK: .calendar (retorna datas futuras/recentes)
        # Só usamos se .earnings_dates falhar
        elif ticker_obj.calendar and 'Earnings Date' in ticker_obj.calendar:
            dates = ticker_obj.calendar['Earnings Date']
            if isinstance(dates, list):
                # Garante que pegamos apenas objetos 'date'
                all_dates = [d for d in dates if isinstance(d, dt.date)]
            elif isinstance(dates, dt.date):
                all_dates = [dates]

        # Armazena se encontramos alguma data
        if all_dates:
            # Remove duplicatas e ordena
            earnings_calendar[ticker_str] = sorted(list(set(all_dates)))
        else:
            failed_tickers.append(ticker_str)

    except Exception as e:
        # Captura erros de tickers que podem ter problemas na API
        failed_tickers.append(ticker_str)

print("\nBusca de calendário concluída.")
print(f"Sucesso na obtenção de dados de 'earnings' para {len(earnings_calendar)} tickers.")
print(f"Falha (sem dados de 'earnings') para {len(failed_tickers)} tickers.")

if failed_tickers:
    print(f"Tickers com falha: {failed_tickers}")

# Exemplo de saída (agora padronizado e mostrando o histórico)
if 'NVDA' in earnings_calendar:
    print(f"\nExemplo de dados 'earnings' (NVDA) [As 5 datas MAIS ANTIGAS]:")
    print(earnings_calendar['NVDA'][:5]) # Mostra as 5 primeiras (mais antigas)
    print(f"\nExemplo de dados 'earnings' (NVDA) [As 5 datas MAIS RECENTES]:")
    print(earnings_calendar['NVDA'][-5:]) # Mostra as 5 últimas (mais recentes)

# Célula 5 (REVISADA): Análise Crítica (Corrigindo o TypeError)

if not earnings_calendar:
    print("ERRO CRÍTICO: Nenhum dado de calendário de 'earnings' foi coletado.")

else:
    total_events = 0
    historical_events_found = 0

    # --- CORREÇÃO DO TYPEERROR ---
    # Definimos o cutoff como um objeto datetime.date, não um Timestamp.
    cutoff_date = dt.date(2023, 1, 1)

    for ticker, dates in earnings_calendar.items():
        if isinstance(dates, list):
            total_events += len(dates)
            for d in dates:
                # Agora 'd' (que padronizamos para datetime.date na Célula 4)
                # e 'cutoff_date' (datetime.date) são tipos compatíveis.
                if d < cutoff_date:
                    historical_events_found += 1

    print(f"Total de 'eventos' (datas de earnings) encontrados: {total_events}")
    print(f"Total de eventos históricos (antes de 2023) encontrados: {historical_events_found}")

    # Validação da suficiência dos dados
    if historical_events_found < 1000:
        print("\n--- AVISO DE METODOLOGIA (CONFIRMADO) ---")
        print(f"O histórico de datas de 'earnings' obtido via 'yfinance' ({historical_events_found} eventos < 2023) é INSUFICIENTE para um backtest de 10-15 anos.")
        print("Como previsto, 'yfinance' não fornece o histórico completo.")
        print("Prosseguiremos com a amostra que temos, mas o 'N' (significância estatística) será baixo.")
        print("Esta é a principal limitação da Fase 1 e DEVE ser destacada no relatório.")
    else:
         print("\nValidação OK: 'yfinance.earnings_dates' retornou um histórico de eventos suficiente para prosseguir.")

# Célula 6 (REVISADA E CORRIGIDA v3): Mapeamento de Eventos (T) para Dias de Trade (T+1)

print("Iniciando a Fase 2: Geração de Sinais...")

# --- CORREÇÃO DO TYPEERROR ---
# O índice de price_data já é 'naive' (sem fuso).
# Nós apenas o normalizamos (removemos o horário) e pegamos os dias únicos.
all_trading_days = pd.to_datetime(price_data.index).normalize().unique()
all_trading_days = all_trading_days.sort_values()


# Lista para armazenar cada evento (cada linha do nosso futuro DataFrame)
events_list = []

print(f"Mapeando {total_events} eventos para {len(tickers_n100_clean)} tickers...")

for ticker in tqdm(tickers_n100_clean, desc="Processando Tickers"):
    if ticker not in earnings_calendar:
        continue # Ticker não tem datas de earnings

    # Pega os dados de preço (Open e Close) APENAS para este ticker
    ticker_prices = price_data.loc[:, (['Open', 'Close'], ticker)].stack()
    if ticker_prices.empty:
        continue

    # Pega as datas de earnings deste ticker
    for earnings_date in earnings_calendar[ticker]:

        # Convertemos a data do evento para Timestamp, mas a mantemos NAIVE (sem fuso).
        # Agora ela é compatível com 'all_trading_days' (que também é naive).
        date_T = pd.to_datetime(earnings_date)

        # 1. Encontrar o dia T (ou o dia de negociação logo ANTES, se T caiu em fds)
        try:
            # Usamos get_indexer() que aceita 'method' e retorna a localização inteira
            trading_day_T_loc_array = all_trading_days.get_indexer([date_T], method='ffill')

            trading_day_T_loc = trading_day_T_loc_array[0]

            if trading_day_T_loc == -1:
                continue # Data do evento é anterior ao nosso início de dados

            trading_day_T = all_trading_days[trading_day_T_loc]

        except KeyError:
            continue # Data do evento fora do range de dados

        # 2. Encontrar o dia T+1 (o dia do trade)
        if trading_day_T_loc + 1 >= len(all_trading_days):
            continue # O evento é o último dia de dados; não há T+1

        trading_day_T1 = all_trading_days[trading_day_T_loc + 1]

        # 3. Armazena os dados do evento
        events_list.append({
            'Ticker': ticker,
            'Date_T_Event': earnings_date, # A data "real" do calendário
            'Date_T_Close': trading_day_T, # O dia que usamos para pegar o Close
            'Date_T1_Open': trading_day_T1  # O dia que usamos para pegar o Open (dia do trade)
        })

# Cria o DataFrame mestre de eventos
events_df = pd.DataFrame(events_list)

# Remove duplicatas que podem surgir se a data do evento (ex: Sábado) e
# (ex: Domingo) mapearem para a mesma Sexta-feira (Date_T_Close)
events_df = events_df.drop_duplicates(subset=['Ticker', 'Date_T_Close'])

print(f"\nDataFrame de eventos brutos criado com {len(events_df)} eventos mapeados.")
print("Exemplo (head):")
print(events_df.head())
print(events_df.tail())

# Célula 7: Cálculo do Sinal (Gap_%) e Retornos Futuros

print("Calculando Sinais (Gap_%) e Retornos Futuros...")

# Definindo as janelas de holding (N) que queremos testar
# (1 dia, 2 dias, 3 dias, 1 semana, 2 semanas, 1 mês)
holding_periods_N = [1, 2, 3, 5, 10, 20]

# Listas para armazenar os resultados
gaps = []
future_returns = {N: [] for N in holding_periods_N} # Dicionário de listas

for idx, event in tqdm(events_df.iterrows(), total=events_df.shape[0], desc="Calculando Sinais"):
    ticker = event['Ticker']
    date_T = event['Date_T_Close']
    date_T1 = event['Date_T1_Open']

    try:
        # 1. Pega os preços relevantes
        close_T = price_data.loc[date_T, ('Close', ticker)]
        open_T1 = price_data.loc[date_T1, ('Open', ticker)]

        # Validação: Ignora se os dados de preço estiverem faltando
        if pd.isna(close_T) or pd.isna(open_T1) or close_T == 0:
            gaps.append(np.nan)
            for N in holding_periods_N:
                future_returns[N].append(np.nan)
            continue

        # 2. Cálculo do Sinal (Gap_%)
        gap_pct = (open_T1 - close_T) / close_T
        gaps.append(gap_pct)

        # 3. Cálculo dos Retornos Futuros (Nossa Hipótese: Drift)
        #    Entra em Open[T+1], Sai em Close[T+N]

        # Pega a localização de T+1 no índice de dias de negociação
        t1_loc = all_trading_days.get_loc(date_T1)

        for N in holding_periods_N:
            # Encontra a data T+N
            if t1_loc + (N - 1) < len(all_trading_days):
                date_TN_close = all_trading_days[t1_loc + (N - 1)] # N=1 -> T+0 (próprio T1)

                # Pega o preço de fechamento em T+N
                close_TN = price_data.loc[date_TN_close, ('Close', ticker)]

                if pd.isna(close_TN) or open_T1 == 0:
                    future_returns[N].append(np.nan)
                    continue

                # Calcula o retorno do HODLING
                ret_N = (close_TN - open_T1) / open_T1
                future_returns[N].append(ret_N)
            else:
                # Ocorre se o evento estiver muito perto do fim do dataset
                future_returns[N].append(np.nan)

    except Exception as e:
        # Captura erros (ex: dados de preço faltando)
        gaps.append(np.nan)
        for N in holding_periods_N:
            future_returns[N].append(np.nan)

# Adiciona os resultados ao DataFrame de Eventos
events_df['Gap_Pct'] = gaps

for N in holding_periods_N:
    events_df[f'Return_N{N}'] = future_returns[N]

# Limpa o DataFrame de eventos com dados NaN (falhas de cálculo)
events_df_clean = events_df.dropna()

print("\nFase 2 Concluída: DataFrame de Sinais e Retornos está pronto.")
print(f"Eventos válidos (sem NaN): {len(events_df_clean)} / {len(events_df)}")
print("Exemplo (head):")
# Mostra apenas as colunas relevantes
print(events_df_clean[['Ticker', 'Date_T_Event', 'Gap_Pct', 'Return_N1', 'Return_N5', 'Return_N20']].head())

print("\nAnálise descritiva do Sinal (Gap_Pct):")
print(events_df_clean['Gap_Pct'].describe())

# Célula 8 (REVISADA): Função de Backtest com Seletor de Direção

import matplotlib.pyplot as plt
import seaborn as sns

# Configura o estilo do seaborn para os gráficos
sns.set(style='darkgrid')

def run_backtest(events_data, holding_period_N, gap_threshold_pct, transaction_cost_pct, direction='momentum'):
    """
    Executa a simulação da estratégia com base nos parâmetros fornecidos.

    Args:
    events_data (pd.DataFrame): O DataFrame 'events_df_clean'.
    holding_period_N (int): Dias 'N' para manter a posição.
    gap_threshold_pct (float): Gap mínimo para operar.
    transaction_cost_pct (float): Custo por transação.
    direction (str): 'momentum' (operar a favor do gap) ou 'reversion' (operar contra o gap).

    Returns:
    pd.Series: Uma série de retornos (indexada pela data do trade).
    pd.DataFrame: Um DataFrame de trades filtrados.
    """

    # 1. Validação do Período de Retorno
    return_column = f'Return_N{holding_period_N}'
    if return_column not in events_data.columns:
        print(f"ERRO: Coluna de retorno '{return_column}' não encontrada.")
        return None, None

    # 2. Filtragem de Sinais (Regra de Decisão)
    trades_df = events_data[
        events_data['Gap_Pct'].abs() >= gap_threshold_pct
    ].copy()

    if trades_df.empty:
        return pd.Series(dtype=float), pd.DataFrame()

    # 3. Definição da Direção
    base_direction = np.sign(trades_df['Gap_Pct'])

    if direction == 'momentum':
        trades_df['Direction'] = base_direction
    elif direction == 'reversion':
        trades_df['Direction'] = -base_direction # Inverte a direção
    else:
        raise ValueError("Argumento 'direction' deve ser 'momentum' ou 'reversion'")

    # 4. Cálculo do Retorno da Estratégia
    trades_df['Gross_Return'] = trades_df[return_column] * trades_df['Direction']

    # 5. Aplicação de Custos de Transação
    trades_df['Net_Return'] = trades_df['Gross_Return'] - (2 * transaction_cost_pct)

    strategy_returns = trades_df[['Date_T1_Open', 'Net_Return']].set_index('Date_T1_Open')
    strategy_returns.index.name = 'Date'

    return strategy_returns, trades_df

print("Célula 8 (REVISADA): Função 'run_backtest' com seletor de direção definida.")

# Célula 9: Fase 4 - Execução do Backtest (Caso Base)

# --- Parâmetros do Caso Base ---
N_base = 5              # Holding de 5 dias
THRESHOLD_base = 0.02   # Gap mínimo de 2% (próximo do 25%/75% que vimos)
COST_base = 0.0005      # 0.05% (5 bps) por transação

print(f"Executando Backtest - Caso Base (N={N_base}, Threshold={THRESHOLD_base*100}%)")

# Executa a função
returns_base, trades_base = run_backtest(events_df_clean, N_base, THRESHOLD_base, COST_base)

if returns_base is not None and not returns_base.empty:
    # --- Métricas de Performance ---
    N_trades = len(returns_base)
    Win_Rate = (returns_base['Net_Return'] > 0).mean()
    Avg_Return = returns_base['Net_Return'].mean()
    Std_Return = returns_base['Net_Return'].std()

    # O Sharpe Ratio "por trade" (Return / Volatility) é a métrica
    # mais robusta para avaliar estratégias de eventos.
    Sharpe_Trades = 0
    if Std_Return > 0:
        Sharpe_Trades = Avg_Return / Std_Return

    print("\n--- Resultados do Caso Base ---")
    print(f"Período de Dados (Eventos): {events_df_clean['Date_T_Event'].min()} a {events_df_clean['Date_T_Event'].max()}")
    print(f"Total de Trades Executados: {N_trades} (de {len(events_df_clean)} eventos válidos)")
    print(f"Taxa de Acerto (Win Rate): {Win_Rate:.2%}")
    print(f"Retorno Médio por Trade: {Avg_Return:.4%}")
    print(f"Sharpe Ratio (por Trade): {Sharpe_Trades:.3f}")

    # Plotando a Curva de Capital (Retorno Acumulado)
    plt.figure(figsize=(12, 6))
    plt.title(f'Curva de Capital (Log) - Estratégia PEAD via Gap (N={N_base}, Thresh={THRESHOLD_base*100}%)')

    # Ordena os retornos pela data para o gráfico
    cumulative_log_returns = np.log1p(returns_base.sort_index()['Net_Return']).cumsum()
    cumulative_log_returns.plot()

    plt.ylabel('Retorno Log Acumulado')
    plt.xlabel('Data do Trade')
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.show()

else:
    print("Backtest não gerou resultados para os parâmetros do Caso Base.")

# Célula 10: Fase 4 - Análise de Sensibilidade (Holding Period 'N')

print("Iniciando Análise de Sensibilidade 1: Período de Holding (N)")

# Usamos os N's que já calculamos na Fase 2
holding_periods_to_test = [1, 2, 3, 5, 10, 20]

# Usamos o mesmo Threshold e Custo do Caso Base
base_threshold = 0.02
base_cost = 0.0005

results_by_N = []

for N in tqdm(holding_periods_to_test, desc="Testando N"):
    returns_n, trades_n = run_backtest(events_df_clean, N, base_threshold, base_cost)

    if returns_n is not None and not returns_n.empty:
        avg_ret = returns_n['Net_Return'].mean()
        std_ret = returns_n['Net_Return'].std()

        # Evita divisão por zero se houver apenas 1 trade ou std = 0
        if std_ret > 0:
            sharpe_n = avg_ret / std_ret
        else:
            sharpe_n = 0

        results_by_N.append({
            'N_Holding': N,
            'Sharpe_Ratio_Trade': sharpe_n,
            'Avg_Return_Trade': avg_ret,
            'N_Trades': len(returns_n)
        })

# Cria um DataFrame com os resultados
results_N_df = pd.DataFrame(results_by_N)

print("\nResultados da Análise de Sensibilidade (N):")
print(results_N_df)

# --- Plotagem (A Prova Visual da Hipótese) ---
if not results_N_df.empty:
    plt.figure(figsize=(12, 6))

    # Plotagem do Sharpe Ratio
    ax1 = plt.gca()
    sns.lineplot(data=results_N_df, x='N_Holding', y='Sharpe_Ratio_Trade', marker='o', ax=ax1, label='Sharpe Ratio (por Trade)', color='blue')
    ax1.set_ylabel('Sharpe Ratio (por Trade)')
    ax1.set_xlabel('Dias de Holding (N)')
    ax1.axhline(0, color='red', linestyle='--', linewidth=1)

    # Plotagem do Retorno Médio (Eixo Y secundário)
    ax2 = ax1.twinx()
    sns.lineplot(data=results_N_df, x='N_Holding', y='Avg_Return_Trade', marker='s', ax=ax2, label='Retorno Médio (por Trade)', color='green', alpha=0.6)
    ax2.set_ylabel('Retorno Médio (por Trade)')

    plt.title(f'Análise de Sensibilidade (N) vs. Performance (Threshold={base_threshold*100}%)')
    plt.grid(True, linestyle='--', alpha=0.5)

    # Ajusta legendas
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
    ax1.legend().set_visible(False) # A legenda combinada já está em ax2

    plt.show()
else:
    print("Nenhuma simulação foi bem-sucedida na análise de sensibilidade.")

# Célula 11: Fase 4 - Análise de Sensibilidade (Gap Threshold)

print("Iniciando Análise de Sensibilidade 2: Gap Threshold (para Momentum)")

# Vamos testar thresholds de 1% a 10%
thresholds_to_test = [0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.10]

# Usamos o "melhor" N da análise anterior (N=10)
# e a direção 'momentum' (padrão)
fixed_N = 10
base_cost = 0.0005

results_by_T = []

for T in tqdm(thresholds_to_test, desc="Testando Thresholds"):
    returns_t, trades_t = run_backtest(events_df_clean, fixed_N, T, base_cost, direction='momentum')

    if returns_t is not None and not returns_t.empty:
        avg_ret = returns_t['Net_Return'].mean()
        std_ret = returns_t['Net_Return'].std()
        sharpe_t = (avg_ret / std_ret) if std_ret > 0 else 0

        results_by_T.append({
            'Threshold_Pct': T * 100, # (em %)
            'Sharpe_Ratio_Trade': sharpe_t,
            'Avg_Return_Trade': avg_ret,
            'N_Trades': len(returns_t)
        })

# Cria um DataFrame com os resultados
results_T_df = pd.DataFrame(results_by_T)

print("\nResultados da Análise de Sensibilidade (Threshold):")
print(results_T_df)

# --- Plotagem (Rigor vs. N) ---
# Um Sharpe alto com N baixo (poucos trades) é overfitting.
if not results_T_df.empty:
    fig, ax1 = plt.subplots(figsize=(12, 6))

    # Plotagem do Sharpe Ratio
    sns.lineplot(data=results_T_df, x='Threshold_Pct', y='Sharpe_Ratio_Trade', marker='o', ax=ax1, label='Sharpe Ratio (por Trade)', color='blue')
    ax1.set_ylabel('Sharpe Ratio (por Trade)')
    ax1.set_xlabel('Gap Threshold Mínimo (%)')
    ax1.axhline(0, color='red', linestyle='--', linewidth=1)

    # Plotagem do N_Trades (Eixo Y secundário)
    ax2 = ax1.twinx()
    sns.barplot(data=results_T_df, x='Threshold_Pct', y='N_Trades', ax=ax2, label='Nº de Trades', color='gray', alpha=0.4)
    ax2.set_ylabel('Nº de Trades')
    ax2.grid(False) # Desliga a grade do eixo secundário

    fig.suptitle(f'Análise de Sensibilidade (Threshold) vs. Performance (Momentum, N={fixed_N})')

    # Ajusta legendas
    lines1, labels1 = ax1.get_legend_handles_labels()
    bars2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + [bars2], labels1 + [labels2], loc='upper center')
    ax1.legend().set_visible(False)

    plt.show()
else:
    print("Nenhuma simulação foi bem-sucedida na análise de sensibilidade.")

# Célula 12 (REVISADA E CORRIGIDA): Teste da Hipótese 2 (Reversão à Média)

print("Iniciando Teste de Hipótese 2: Reversão à Média (vs. N)")

# Usamos os N's que já calculamos
holding_periods_to_test = [1, 2, 3, 5, 10, 20]

# Usamos o Threshold e Custo do Caso Base
base_threshold = 0.02
base_cost = 0.0005

results_reversion_N = []

for N in tqdm(holding_periods_to_test, desc="Testando Reversão (N)"):
    # A MUDANÇA CRÍTICA: direction='reversion'
    returns_n, trades_n = run_backtest(events_df_clean, N, base_threshold, base_cost, direction='reversion')

    if returns_n is not None and not returns_n.empty:
        avg_ret = returns_n['Net_Return'].mean()
        std_ret = returns_n['Net_Return'].std()
        sharpe_n = (avg_ret / std_ret) if std_ret > 0 else 0

        results_reversion_N.append({
            'N_Holding': N,
            'Sharpe_Ratio_Trade': sharpe_n,
            'Avg_Return_Trade': avg_ret,
            'N_Trades': len(returns_n)
        })

# Cria um DataFrame com os resultados
results_reversion_N_df = pd.DataFrame(results_reversion_N)

print("\nResultados da Análise de Reversão (vs. N):")
print(results_reversion_N_df)

# --- Plotagem (A Prova Visual da Hipótese) ---
if not results_reversion_N_df.empty:
    plt.figure(figsize=(12, 6))

    # Plotagem do Sharpe Ratio
    ax1 = plt.gca()
    sns.lineplot(data=results_reversion_N_df, x='N_Holding', y='Sharpe_Ratio_Trade', marker='o', ax=ax1, label='Sharpe Ratio (Reversão)', color='red')
    ax1.set_ylabel('Sharpe Ratio (por Trade)')
    ax1.set_xlabel('Dias de Holding (N)')
    ax1.axhline(0, color='black', linestyle='--', linewidth=1)

    # Plotagem do Retorno Médio (Eixo Y secundário)
    ax2 = ax1.twinx()

    # --- CORREÇÃO DO ATTRIBUTEERROR ---
    # O argumento deve ser 'ax=ax2' (o objeto) e não 'ax=2' (o inteiro)
    sns.lineplot(data=results_reversion_N_df, x='N_Holding', y='Avg_Return_Trade', marker='s', ax=ax2, label='Retorno Médio (Reversão)', color='orange', alpha=0.6)
    ax2.set_ylabel('Retorno Médio (por Trade)')
    ax2.grid(False) # Desliga a grade do eixo secundário

    plt.title(f'Análise da Hipótese de REVERSÃO (N) vs. Performance (Threshold={base_threshold*100}%)')

    # Ajusta legendas
    lines1, labels1 = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
    ax1.legend().set_visible(False)

    plt.show()
else:
    print("Nenhuma simulação de reversão foi bem-sucedida.")